{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO_discrete.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3nfljasa3N3R/SHNcgnjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NonMagneticNeedle/reinforcement_learning/blob/master/ppo_tf.keras/PPO_discrete_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35COzX11cbLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdf1e49b-6f0a-418a-d533-5dcad84f0130"
      },
      "source": [
        "# the current policy which we use to sample data , the sampled data automatically becomes the old policy data once we start training \n",
        "#the policy net for more than 1 epoch  \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "#env=gym.make('Acrobot-v1')\n",
        "env=gym.make('CartPole-v1')\n",
        "#env=gym.make('MountainCar-v0')\n",
        "env=env.unwrapped#removes step restriction\n",
        "\n",
        "s_dim = env.observation_space.shape[0]\n",
        "print(s_dim)\n",
        "a_dim = env.action_space.n\n",
        "print(a_dim)\n",
        "#a_bound = env.action_space.high\n",
        "#print(a_bound)\n",
        "DUMMY_ACTION, DUMMY_VALUE = np.zeros((1,a_dim)), np.zeros((1, 1))\n",
        "\n",
        "\n",
        "\n",
        "state_inputs = tf.keras.Input(shape=(s_dim,), name='state')\n",
        "advantage = tf.keras.Input(shape=(1, ), name=\"Advantage\")\n",
        "old_prediction = tf.keras.Input(shape=(a_dim,), name=\"Old_Prediction\")\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(state_inputs)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "action_outputs = tf.keras.layers.Dense(a_dim, activation='softmax')(x)\n",
        "\n",
        "\n",
        "def proximal_policy_optimization_loss(advantage, old_prediction):\n",
        "\tloss_clipping = 0.2\n",
        "\tentropy_loss = 0.0\n",
        "\t#y_true = one hot actions , y_pred = prob output\n",
        "\tdef loss(y_true, y_pred):\n",
        "\t\tprob = y_true * y_pred\n",
        "\t\told_prob = y_true * old_prediction\n",
        "\t\tr = prob / (old_prob + 1e-10)\n",
        "\t\tloss = -tf.keras.backend.mean(tf.keras.backend.minimum(r * advantage, tf.keras.backend.clip(r, min_value=1 - loss_clipping,max_value=1 + loss_clipping) * advantage) + entropy_loss * (prob * tf.keras.backend.log(prob + 1e-10)))\n",
        "\t\treturn loss\n",
        "\treturn loss\t\n",
        "policy= tf.keras.Model(inputs=[state_inputs, advantage, old_prediction], outputs=[action_outputs], name='p_actor_model')\n",
        "policy.compile(loss=proximal_policy_optimization_loss(advantage=advantage,old_prediction=old_prediction), optimizer=tf.keras.optimizers.Adam(lr=0.0001))# custom lAdam(lr=0.0001) to be defined\n",
        "policy.summary()\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(state_inputs)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "value_outputs = tf.keras.layers.Dense(1, activation=None)(x)\n",
        "critic= tf.keras.Model(inputs=state_inputs, outputs=value_outputs, name='p_critic_model')\n",
        "critic.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "critic.summary()\n",
        "\n",
        "\n",
        "def max(a,b):\n",
        "\tif a>b:\n",
        "\t\treturn a\n",
        "\telse:\n",
        "\t\treturn b\n",
        "def abs(a):\n",
        "\tif a>=0:\n",
        "\t\treturn a\n",
        "\telse:\n",
        "\t\treturn -a\n",
        "\n",
        "\n",
        "class Memory:\n",
        "\tdef __init__(self):\n",
        "\t\tself.batch_s = []\n",
        "\t\tself.batch_a = []\n",
        "\t\tself.batch_r = []\n",
        "\t\tself.batch_s_ = []\n",
        "\t\tself.batch_done = []\n",
        "\t\tself.batch_pred =[]\n",
        "\n",
        "\tdef store(self, s, a, s_, r, done,pred):\n",
        "\t\tself.batch_s.append(s)\n",
        "\t\tself.batch_a.append(a)\n",
        "\t\tself.batch_r.append(r)\n",
        "\t\tself.batch_s_.append(s_)\n",
        "\t\tself.batch_done.append(done)\n",
        "\t\tself.batch_pred.append(pred)    \n",
        "\n",
        "\tdef clear(self):\n",
        "\t\tself.batch_s.clear()\n",
        "\t\tself.batch_a.clear()\n",
        "\t\tself.batch_r.clear()\n",
        "\t\tself.batch_s_.clear()\n",
        "\t\tself.batch_done.clear()\n",
        "\t\tself.batch_pred.clear()    \n",
        "\n",
        "\tdef cnt_samples(self):\n",
        "\t\treturn len(self.batch_s)\n",
        "def onehot(a,s):\n",
        "\ti = np.zeros(a_dim)\n",
        "\ti[a]=1\n",
        "\treturn i\n",
        "def save_weights():\n",
        "\tactorpath=r\"C:\\\\Users\\\\Dell\\\\Desktop\\\\holidASY\\\\my_ppo\\\\ppo_tf.keras\\\\ppo_simple_actor.h5\"\n",
        "\tcriticpath=r\"C:\\\\Users\\\\Dell\\\\Desktop\\\\holidASY\\\\my_ppo\\\\ppo_tf.keras\\\\ppo_simple_critic.h5\"\n",
        "\tpolicy.save_weights(actorpath)\n",
        "\tcritic.save_weights(criticpath)\n",
        "\tprint(\"saved\")\n",
        "def load_weights():\n",
        "\tactorpath=r\"C:\\\\Users\\\\Dell\\\\Desktop\\\\holidASY\\\\my_ppo\\\\ppo_tf.keras\\\\ppo_simple_actor.h5\"\n",
        "\tcriticpath=r\"C:\\\\Users\\\\Dell\\\\Desktop\\\\holidASY\\\\my_ppo\\\\ppo_tf.keras\\\\ppo_simple_critic.h5\"\n",
        "\tpolicy.load_weights(actorpath)\n",
        "\tcritic.load_weights(criticpath)\n",
        "\tprint(\"loaded\")\n",
        "\n",
        "def gae_calc(val,val_,rew,done):\n",
        "\tmask=1 \n",
        "\tgae=0\n",
        "\tgamma=0.99\n",
        "\tlambd = 0.95\n",
        "\treturns=np.zeros_like(val)\n",
        "\tfor i in reversed(range(0,len(val))):\n",
        "\t\tmask=1\n",
        "\t\tif done[i]:\n",
        "\t\t\tmask = 0 \t\n",
        "\t\tdelta=rew[i]+gamma*val_[i]*mask - val[i]\n",
        "\t\tgae=delta+gamma*lambd*mask*gae\n",
        "\t\treturns[i]=gae+val[i]\n",
        "\treturn returns\n",
        "\t\n",
        "\n",
        "\n",
        "\n",
        "episodes = 2000\n",
        "steps = 200\n",
        "memory=Memory()\n",
        "render=0\n",
        "s=env.reset()\n",
        "for episode in range(1,episodes):\n",
        "\trew = 0\n",
        "\tif episode>220:\n",
        "\t\trender=1\n",
        "\tfor step in range(steps):\n",
        "\t\tif render:\n",
        "\t\t\tenv.render()\n",
        "\t\tpred_action = policy.predict([np.array([s]),DUMMY_VALUE,DUMMY_ACTION])# prob distribution\n",
        "\t\taction = np.random.choice(np.arange(pred_action.shape[1]), p=pred_action.ravel())# action chosen\n",
        "\t\t#random_action= np.random.choice(np.arange(pred_action.shape[1]))\n",
        "\t\t#if steps% 3 == 0 and episode<50:\n",
        "\t\t#\taction = random_action\n",
        "\t\taction_one_hot=onehot(action,a_dim)# acton matrix\n",
        "\t\ts_, reward, done, info = env.step(action)\n",
        "\t\tmemory.store(s.ravel(),action_one_hot.ravel(),s_.ravel(),reward,done,pred_action.ravel())# s, a, s_, r, done ,pred\n",
        "\t\tif done:\n",
        "\t\t\tprint(rew, end ='')\n",
        "\t\t\ts_=env.reset()\n",
        "\t\t\trew = 0 \n",
        "\t\ts=s_\n",
        "\t\trew+=reward\n",
        "\t# updation\n",
        "\tobs =np.array( memory.batch_s)\n",
        "\tvalues = critic.predict(np.array(memory.batch_s))\n",
        "\tvalues_ = critic.predict(np.array(memory.batch_s_))\n",
        "\treturns = gae_calc(values,values_,memory.batch_r,memory.batch_done)\t\n",
        "\tadvantage=returns-values\n",
        "\told_Prediction=memory.batch_pred\n",
        "\told_Prediction=np.array(old_Prediction)\n",
        "\taction=np.array(memory.batch_a)########################\n",
        "\tprint(\".\")\n",
        "\tprint(episode)\n",
        "\tpolicy.fit(x=[obs,advantage, old_Prediction],y=action,batch_size=64,shuffle=True, epochs=10, verbose=False)\n",
        "\tcritic.fit([obs],[returns], batch_size=64, shuffle=True, epochs=10, verbose=False)\n",
        "\t#print(actor_loss,critic_loss)\n",
        "\tmemory.clear()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "Model: \"p_actor_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "state (InputLayer)              [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 64)           320         state[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 64)           4160        dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Advantage (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Old_Prediction (InputLayer)     [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 2)            130         dense_31[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,610\n",
            "Trainable params: 4,610\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"p_critic_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "state (InputLayer)           [(None, 4)]               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 64)                320       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,545\n",
            "Trainable params: 4,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "16.026.027.016.028.020.010.014.017.010.013.0.\n",
            "1\n",
            "18.014.024.019.017.016.013.025.012.012.0.\n",
            "2\n",
            "29.021.017.034.011.031.014.028.0.\n",
            "3\n",
            "4.014.013.022.013.026.013.020.014.018.037.0.\n",
            "4\n",
            "13.012.013.017.014.016.020.021.016.016.016.016.0.\n",
            "5\n",
            "52.018.019.023.014.046.0.\n",
            "6\n",
            "14.022.020.026.021.013.052.0.\n",
            "7\n",
            "8.014.048.025.019.016.064.0.\n",
            "8\n",
            "7.019.017.023.013.016.068.0.\n",
            "9\n",
            "20.011.018.034.026.016.010.023.0.\n",
            "10\n",
            "14.030.018.025.014.016.029.053.0.\n",
            "11\n",
            "20.037.018.019.039.018.021.0.\n",
            "12\n",
            "33.019.058.052.017.0.\n",
            "13\n",
            "10.019.016.021.041.021.044.013.0.\n",
            "14\n",
            "42.025.032.046.021.011.019.0.\n",
            "15\n",
            "92.049.058.0.\n",
            "16\n",
            "46.0106.0.\n",
            "17\n",
            "77.0115.0.\n",
            "18\n",
            "89.096.0.\n",
            "19\n",
            "32.0.\n",
            "20\n",
            "4.0113.068.0.\n",
            "21\n",
            "78.062.0.\n",
            "22\n",
            "65.031.027.0.\n",
            "23\n",
            "149.0.\n",
            "24\n",
            "104.040.0.\n",
            "25\n",
            ".\n",
            "26\n",
            "116.0.\n",
            "27\n",
            "162.0.\n",
            "28\n",
            "166.0.\n",
            "29\n",
            "6.0162.022.0.\n",
            "30\n",
            "185.0.\n",
            "31\n",
            "185.0.\n",
            "32\n",
            "169.0.\n",
            "33\n",
            ".\n",
            "34\n",
            "25.0106.0.\n",
            "35\n",
            "71.0.\n",
            "36\n",
            ".\n",
            "37\n",
            "18.0.\n",
            "38\n",
            "45.0.\n",
            "39\n",
            "30.0.\n",
            "40\n",
            "187.0.\n",
            "41\n",
            ".\n",
            "42\n",
            "1.0.\n",
            "43\n",
            "86.0.\n",
            "44\n",
            "89.0.\n",
            "45\n",
            "118.0.\n",
            "46\n",
            "42.0138.0.\n",
            "47\n",
            ".\n",
            "48\n",
            "42.0.\n",
            "49\n",
            "76.0.\n",
            "50\n",
            "141.0.\n",
            "51\n",
            ".\n",
            "52\n",
            "107.0.\n",
            "53\n",
            "166.0.\n",
            "54\n",
            ".\n",
            "55\n",
            "51.0.\n",
            "56\n",
            ".\n",
            "57\n",
            ".\n",
            "58\n",
            "23.0.\n",
            "59\n",
            ".\n",
            "60\n",
            "41.0.\n",
            "61\n",
            ".\n",
            "62\n",
            "8.0.\n",
            "63\n",
            ".\n",
            "64\n",
            "0.\n",
            "65\n",
            ".\n",
            "66\n",
            ".\n",
            "67\n",
            ".\n",
            "68\n",
            "56.0.\n",
            "69\n",
            ".\n",
            "70\n",
            "28.0.\n",
            "71\n",
            "115.0.\n",
            "72\n",
            "99.0.\n",
            "73\n",
            ".\n",
            "74\n",
            ".\n",
            "75\n",
            "184.0.\n",
            "76\n",
            ".\n",
            "77\n",
            "69.0.\n",
            "78\n",
            "35.0126.0.\n",
            "79\n",
            ".\n",
            "80\n",
            ".\n",
            "81\n",
            "69.0.\n",
            "82\n",
            ".\n",
            "83\n",
            ".\n",
            "84\n",
            "122.0.\n",
            "85\n",
            "71.0.\n",
            "86\n",
            ".\n",
            "87\n",
            ".\n",
            "88\n",
            ".\n",
            "89\n",
            ".\n",
            "90\n",
            ".\n",
            "91\n",
            ".\n",
            "92\n",
            "25.0.\n",
            "93\n",
            ".\n",
            "94\n",
            "189.0.\n",
            "95\n",
            ".\n",
            "96\n",
            ".\n",
            "97\n",
            ".\n",
            "98\n",
            "76.0.\n",
            "99\n",
            ".\n",
            "100\n",
            ".\n",
            "101\n",
            ".\n",
            "102\n",
            ".\n",
            "103\n",
            ".\n",
            "104\n",
            ".\n",
            "105\n",
            ".\n",
            "106\n",
            ".\n",
            "107\n",
            "58.0.\n",
            "108\n",
            ".\n",
            "109\n",
            ".\n",
            "110\n",
            ".\n",
            "111\n",
            "194.0.\n",
            "112\n",
            ".\n",
            "113\n",
            ".\n",
            "114\n",
            "68.0.\n",
            "115\n",
            ".\n",
            "116\n",
            ".\n",
            "117\n",
            ".\n",
            "118\n",
            ".\n",
            "119\n",
            ".\n",
            "120\n",
            ".\n",
            "121\n",
            "48.0.\n",
            "122\n",
            ".\n",
            "123\n",
            ".\n",
            "124\n",
            "154.0.\n",
            "125\n",
            ".\n",
            "126\n",
            ".\n",
            "127\n",
            ".\n",
            "128\n",
            ".\n",
            "129\n",
            "55.0.\n",
            "130\n",
            ".\n",
            "131\n",
            "4.0.\n",
            "132\n",
            ".\n",
            "133\n",
            ".\n",
            "134\n",
            "51.0.\n",
            "135\n",
            ".\n",
            "136\n",
            "28.0.\n",
            "137\n",
            ".\n",
            "138\n",
            ".\n",
            "139\n",
            ".\n",
            "140\n",
            ".\n",
            "141\n",
            ".\n",
            "142\n",
            "117.0.\n",
            "143\n",
            ".\n",
            "144\n",
            ".\n",
            "145\n",
            "96.0.\n",
            "146\n",
            ".\n",
            "147\n",
            ".\n",
            "148\n",
            ".\n",
            "149\n",
            ".\n",
            "150\n",
            ".\n",
            "151\n",
            ".\n",
            "152\n",
            ".\n",
            "153\n",
            ".\n",
            "154\n",
            ".\n",
            "155\n",
            ".\n",
            "156\n",
            ".\n",
            "157\n",
            ".\n",
            "158\n",
            "89.0.\n",
            "159\n",
            ".\n",
            "160\n",
            ".\n",
            "161\n",
            ".\n",
            "162\n",
            ".\n",
            "163\n",
            ".\n",
            "164\n",
            ".\n",
            "165\n",
            ".\n",
            "166\n",
            ".\n",
            "167\n",
            ".\n",
            "168\n",
            ".\n",
            "169\n",
            ".\n",
            "170\n",
            ".\n",
            "171\n",
            ".\n",
            "172\n",
            ".\n",
            "173\n",
            ".\n",
            "174\n",
            ".\n",
            "175\n",
            ".\n",
            "176\n",
            ".\n",
            "177\n",
            ".\n",
            "178\n",
            ".\n",
            "179\n",
            ".\n",
            "180\n",
            ".\n",
            "181\n",
            ".\n",
            "182\n",
            ".\n",
            "183\n",
            ".\n",
            "184\n",
            ".\n",
            "185\n",
            ".\n",
            "186\n",
            ".\n",
            "187\n",
            ".\n",
            "188\n",
            ".\n",
            "189\n",
            ".\n",
            "190\n",
            ".\n",
            "191\n",
            ".\n",
            "192\n",
            ".\n",
            "193\n",
            ".\n",
            "194\n",
            ".\n",
            "195\n",
            ".\n",
            "196\n",
            ".\n",
            "197\n",
            ".\n",
            "198\n",
            ".\n",
            "199\n",
            ".\n",
            "200\n",
            ".\n",
            "201\n",
            ".\n",
            "202\n",
            ".\n",
            "203\n",
            ".\n",
            "204\n",
            ".\n",
            "205\n",
            ".\n",
            "206\n",
            ".\n",
            "207\n",
            ".\n",
            "208\n",
            ".\n",
            "209\n",
            ".\n",
            "210\n",
            ".\n",
            "211\n",
            ".\n",
            "212\n",
            ".\n",
            "213\n",
            ".\n",
            "214\n",
            ".\n",
            "215\n",
            ".\n",
            "216\n",
            ".\n",
            "217\n",
            ".\n",
            "218\n",
            ".\n",
            "219\n",
            ".\n",
            "220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-464acacc9893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mpred_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDUMMY_VALUE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDUMMY_ACTION\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# prob distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# action chosen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     raise ImportError('''\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcompat_platform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcocoa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoaConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToICJjtVfcAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}